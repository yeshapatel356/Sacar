{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Use Watsonx to analyze car rental customer satisfaction and offer recommendation."}, {"metadata": {}, "cell_type": "markdown", "source": "**Note:** Please note that for the watsonx challenge, please run these notebooks in IBM Cloud and not on on your laptop/desktop."}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook contains the steps and code to demonstrate support of text sentiment analysis in Watsonx. It introduces commands for data retrieval, model testing and scoring.\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n## Set up the environment"}, {"metadata": {}, "cell_type": "markdown", "source": "### Install and import the dependecies"}, {"metadata": {}, "cell_type": "code", "source": "!pip install datasets | tail -n 1\n!pip install scikit-learn | tail -n 1\n!pip install ibm-watson-machine-learning==1.0.312 | tail -n 1", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Successfully installed datasets-2.14.6 dill-0.3.7 filelock-3.12.4 fsspec-2023.10.0 huggingface-hub-0.18.0 multiprocess-0.70.15 xxhash-3.4.1\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn) (1.8.1)\nSuccessfully installed ibm-watson-machine-learning-1.0.312\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Note:** Please restart the notebook kernel to pick up proper version of packages installed above."}, {"metadata": {}, "cell_type": "code", "source": "import os, getpass\nfrom pandas import read_csv", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud user API key. Instructions have been provided to generate IBM Cloud API key. For details, see\n[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_cloud_sdk_core import IAMTokenManager\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator, BearerTokenAuthenticator\nimport os, getpass\n\naccess_token = IAMTokenManager(\n    apikey = getpass.getpass(\"Please enter your api key (hit enter): \"),\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n).get_token()", "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Please enter your api key (hit enter): \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the project id\nThe API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. When you run notebook on IBM Cloud, project in which it runs is saved as environment variable PROJECT_ID.\n\n**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n"}, {"metadata": {}, "cell_type": "code", "source": "try:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"data\"></a>\n## Train/test data loading"}, {"metadata": {}, "cell_type": "markdown", "source": "Load train and test datasets. At first, training dataset (`train_data`) should be used to work with the models to prepare and tune prompt. Then, test dataset (`test_data`) should be used to calculate the metrics score for selected model, defined prompts and parameters."}, {"metadata": {}, "cell_type": "code", "source": "filename_test = 'https://watsonx-gsi-challenge.s3.jp-tok.cloud-object-storage.appdomain.cloud/track1/test.csv'\nfilename_train = 'https://watsonx-gsi-challenge.s3.jp-tok.cloud-object-storage.appdomain.cloud/track1/train.csv'\n\ntest_data = read_csv(filename_test)\ntrain_data = read_csv(filename_train)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "train_data.head()", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "     ID  Gender Status  Children    Age Customer_Status Car_Owner  \\\n0  2944  Female      M         2  41.92          Active        No   \n1  1119  Female      M         2  33.60          Active       Yes   \n2     0    Male      M         0  51.00        Inactive       Yes   \n3  1085  Female      S         2  42.00        Inactive        No   \n4     0  Female      M         2  44.10          Active        No   \n\n                                    Customer_Service  Satisfaction  \\\n0         Customer service was friendly and helpful.             1   \n1  Customer service was good at MSP airport and t...             1   \n2  I do not  understand why I have to pay additio...             0   \n3  Based on the customer service personnel I enco...             0   \n4  Provide more convenient car pickup from the ai...             0   \n\n                  Business_Area                     Action  \n0            Service: Knowledge                        NaN  \n1            Service: Knowledge                        NaN  \n2  Product: Pricing and Billing           Premium features  \n3             Service: Attitude  On-demand pickup location  \n4     Service: Orders/Contracts  On-demand pickup location  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gender</th>\n      <th>Status</th>\n      <th>Children</th>\n      <th>Age</th>\n      <th>Customer_Status</th>\n      <th>Car_Owner</th>\n      <th>Customer_Service</th>\n      <th>Satisfaction</th>\n      <th>Business_Area</th>\n      <th>Action</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2944</td>\n      <td>Female</td>\n      <td>M</td>\n      <td>2</td>\n      <td>41.92</td>\n      <td>Active</td>\n      <td>No</td>\n      <td>Customer service was friendly and helpful.</td>\n      <td>1</td>\n      <td>Service: Knowledge</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1119</td>\n      <td>Female</td>\n      <td>M</td>\n      <td>2</td>\n      <td>33.60</td>\n      <td>Active</td>\n      <td>Yes</td>\n      <td>Customer service was good at MSP airport and t...</td>\n      <td>1</td>\n      <td>Service: Knowledge</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Male</td>\n      <td>M</td>\n      <td>0</td>\n      <td>51.00</td>\n      <td>Inactive</td>\n      <td>Yes</td>\n      <td>I do not  understand why I have to pay additio...</td>\n      <td>0</td>\n      <td>Product: Pricing and Billing</td>\n      <td>Premium features</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1085</td>\n      <td>Female</td>\n      <td>S</td>\n      <td>2</td>\n      <td>42.00</td>\n      <td>Inactive</td>\n      <td>No</td>\n      <td>Based on the customer service personnel I enco...</td>\n      <td>0</td>\n      <td>Service: Attitude</td>\n      <td>On-demand pickup location</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Female</td>\n      <td>M</td>\n      <td>2</td>\n      <td>44.10</td>\n      <td>Active</td>\n      <td>No</td>\n      <td>Provide more convenient car pickup from the ai...</td>\n      <td>0</td>\n      <td>Service: Orders/Contracts</td>\n      <td>On-demand pickup location</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "test_data.head()", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "     ID  Gender Status  Children    Age Customer_Status Car_Owner  \\\n0  2771  Female      M         2  49.99        Inactive        No   \n1  1133    Male      S         1  56.05        Inactive        No   \n2   900  Female      M         1  64.64          Active        No   \n3  3795    Male      M         0  46.51        Inactive        No   \n4  3541    Male      S         1  17.01        Inactive       Yes   \n\n                                    Customer_Service  Satisfaction  \\\n0  last time I rented a car was at Manchester, NH...             0   \n1                           Please lower the prices.             0   \n2        Excellent response dealing with child seat.             1   \n3  all went quite smoothly... it was Enterprise, ...             1   \n4                                  Slow, long lineup             0   \n\n                  Business_Area                     Action  \n0          Product: Functioning  On-demand pickup location  \n1  Product: Pricing and Billing               Free Upgrade  \n2        Service: Accessibility                        NaN  \n3        Service: Accessibility                        NaN  \n4          Product: Functioning  On-demand pickup location  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gender</th>\n      <th>Status</th>\n      <th>Children</th>\n      <th>Age</th>\n      <th>Customer_Status</th>\n      <th>Car_Owner</th>\n      <th>Customer_Service</th>\n      <th>Satisfaction</th>\n      <th>Business_Area</th>\n      <th>Action</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2771</td>\n      <td>Female</td>\n      <td>M</td>\n      <td>2</td>\n      <td>49.99</td>\n      <td>Inactive</td>\n      <td>No</td>\n      <td>last time I rented a car was at Manchester, NH...</td>\n      <td>0</td>\n      <td>Product: Functioning</td>\n      <td>On-demand pickup location</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1133</td>\n      <td>Male</td>\n      <td>S</td>\n      <td>1</td>\n      <td>56.05</td>\n      <td>Inactive</td>\n      <td>No</td>\n      <td>Please lower the prices.</td>\n      <td>0</td>\n      <td>Product: Pricing and Billing</td>\n      <td>Free Upgrade</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>900</td>\n      <td>Female</td>\n      <td>M</td>\n      <td>1</td>\n      <td>64.64</td>\n      <td>Active</td>\n      <td>No</td>\n      <td>Excellent response dealing with child seat.</td>\n      <td>1</td>\n      <td>Service: Accessibility</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3795</td>\n      <td>Male</td>\n      <td>M</td>\n      <td>0</td>\n      <td>46.51</td>\n      <td>Inactive</td>\n      <td>No</td>\n      <td>all went quite smoothly... it was Enterprise, ...</td>\n      <td>1</td>\n      <td>Service: Accessibility</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3541</td>\n      <td>Male</td>\n      <td>S</td>\n      <td>1</td>\n      <td>17.01</td>\n      <td>Inactive</td>\n      <td>Yes</td>\n      <td>Slow, long lineup</td>\n      <td>0</td>\n      <td>Product: Functioning</td>\n      <td>On-demand pickup location</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"models\"></a>\n## Foundation Models on Watsonx"}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nBelow code invokes Watson Machine Learning API to invoke Watsonx.ai LLMs\n"}, {"metadata": {}, "cell_type": "code", "source": "import requests\n\nclass Prompt:\n    def __init__(self, access_token, project_id):\n        self.access_token = access_token\n        self.project_id = project_id\n\n    def generate(self, input, model_id, parameters):\n        wml_url = \"https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2023-05-28\"\n        Headers = {\n            \"Authorization\": \"Bearer \" + self.access_token,\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\"\n        }\n        data = {\n            \"model_id\": model_id,\n            \"input\": input,\n            \"parameters\": parameters,\n            \"project_id\": self.project_id\n        }\n        response = requests.post(wml_url, json=data, headers=Headers)\n        if response.status_code == 200:\n            return response.json()[\"results\"][0][\"generated_text\"]\n        else:\n            return response.text", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"predict\"></a>\n## Evaluate the model, prompt and parameters"}, {"metadata": {}, "cell_type": "markdown", "source": "### **1. Customer satisfaction**"}, {"metadata": {}, "cell_type": "markdown", "source": "Define instructions for the model to recognize if customer was satisfied or unsatisfied.\n\n**Note:** Please **start with using [watsonx.ai Prompt Lab](https://dataplatform.cloud.ibm.com/wx/home?context=wx)** to find better prompts that provides you the best result on a small subset training records (under `train_data` variable). Make sure to not run an inference of all of `train_data`, as it'll take a long time to get the results. To get a sample from `train_data`, you can use e.g.`train_data.head(n=10)` to get first 10 records, or `train_data.sample(n=10)` to get random 10 records. Only once you have identified the best performing prompt, update this notebook to use the prompt and compute the metrics on the test data.\n\n**Action:** Please edit the below cell and add your own prompt here. In the below prompt, we have the instruction (first sentence) and one example included in the prompt.  If you want to change the prompt or add your own examples or more examples, please change the below prompt accordingly."}, {"metadata": {}, "cell_type": "code", "source": "satisfaction_instruction = \"\"\"\n\nDecide if customer was satisfied or not based on the given feedback by customer. Respond 1 if satisfied and 0 if unsatisfied.\n\nCustomer service was friendly and helpful.\n\n1\n\nI do not  understand why I have to pay additional fee if vehicle is returned without a full tank.\n\n0\n\n\"\"\"", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "train_df_new = train_data.sample(frac = 1).reset_index().head(20)\nprompt_input = \"\"\"Decide if customer was satisfied or not based on the given feedback by customer. Respond 1 if satisfied and 0 if unsatisfied.\\n\"\"\"\n\nfor index, row in train_df_new.iterrows():  \n    prompt_input = prompt_input +\"\"\"\\n\\nReview:\\n{}\\n\\nClassification:\\n{}\\n\"\"\".format(row[\"Customer_Service\"], row[\"Satisfaction\"])", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the model parameters\nWe need to provide a set of model parameters that will influence the result. We will use IBM's Granite model."}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 1,\n    \"min_new_tokens\": 1,\n    \"repetition_penalty\": 1\n}\n\nmodel_id = \"ibm/granite-13b-instruct-v1\"", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Analyze the customer satisfaction for inputs from the test set.\n\n**Note:** Execution of this cell could take several minutes."}, {"metadata": {}, "cell_type": "code", "source": "prompt = Prompt(access_token, project_id)", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\ntest_data[\"Predicted_Satisfaction\"] = 0\nfor index, row in test_data.iterrows():\n    #test = test + \"\"\"\\nReview:\\n{}\\n\\nClassification:\\n\"\"\".format(row[\"Customer_Service\"])\n    generated_response = prompt.generate(prompt_input + \"\"\"\\nReview:\\n{}\\n\\nClassification:\\n\"\"\".format(row[\"Customer_Service\"]), model_id, parameters)\n    test_data.at[index, \"Predicted_Satisfaction\"] = generated_response\n    \n\ntest_data[\"Predicted_Satisfaction\"] = np.where(test_data[\"Predicted_Satisfaction\"]== '', 0, test_data[\"Predicted_Satisfaction\"])", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Calculate the F1 micro score"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import f1_score\n\nprint('f1_micro_score', f1_score(test_data[\"Satisfaction\"].astype(int), test_data[\"Predicted_Satisfaction\"].astype(int), average='micro'))", "execution_count": 37, "outputs": [{"output_type": "stream", "text": "f1_micro_score 0.9\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### **2. Offer Recommendation**"}, {"metadata": {}, "cell_type": "markdown", "source": "Define instructions for the model to recommend best offer to an unsatisfied customer.\n\n**Note:** Please **start with using [watsonx.ai Prompt Lab](https://dataplatform.cloud.ibm.com/wx/home?context=wx)** to find better prompts that provides you the best result on a small subset training records (under `train_data` variable). Make sure to not run an inference of all of `train_data`, as it'll take a long time to get the results. To get a sample from `train_data`, you can use e.g.`train_data.head(n=10)` to get first 10 records, or `train_data.sample(n=10)` to get random 10 records. Only once you have identified the best performing prompt, update this notebook to use the prompt and compute the metrics on the test data.\n\n**Action:** Please edit the below cell and add your own prompt here. In the below prompt, we have the instruction (first sentence) and one example included in the prompt.  If you want to change the prompt or add your own examples or more examples, please change the below prompt accordingly."}, {"metadata": {}, "cell_type": "code", "source": "offer_recommendation_instruction = \"\"\"Generate next best offer to unsatisfied customer. Choose offer recommendation from the following list: 'On-demand pickup location', 'Free Upgrade', 'Voucher', 'Premium features'.\n\nI do not  understand why I have to pay additional fee if vehicle is returned without a full tank.\n\nPremium features\n\nBased on the customer service personnel I encountered most recently, I would say it is vastly preferable for the personnel to be able to at least pretend to care whether the customer ever actually receives a car rental that was reserved months in advance.\n\nOn-demand pickup location\n\nVERY slow service!\n\nFree Upgrade\n\nIt was absolutely ATROCIOUS! My wife and I were in a foreign country  when we realized that our car had an expired license plate and expired proof of insurance!\n\nVoucher\n\nProvide more convenient car pickup from the airport parking.\n\nOn-demand pickup location\n\nThey could really try work harder.\n\nFree Upgrade\n\nI had to wait in line for a long time to get and return the vehicle.  Also, the car was not clean.\n\nVoucher\n\nI would like the reps be knowledgeable about the immediate area around the rental agency and or have maps for the area available free of charge.\n\nPremium features\\n\\n\n\"\"\"", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Defining the model parameters\nWe need to provide a set of model parameters that will influence the result. We will use IBM's Granite model."}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 30,\n    \"min_new_tokens\": 1,\n    \"repetition_penalty\": 1\n}\n\nmodel_id = \"ibm/granite-13b-instruct-v1\"", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Filter test data for unsatisfied customer"}, {"metadata": {}, "cell_type": "code", "source": "train_df_new = train_data[train_data['Satisfaction']== 0].sample(frac = 1).reset_index().head(20)\nprompt_input = \"\"\"Generate next best offer to unsatisfied customer. Choose offer recommendation from the following list: 'On-demand pickup location', 'Free Upgrade', 'Voucher', 'Premium features'.\\n\"\"\"\n\nfor index, row in train_df_new.iterrows():  \n    prompt_input = prompt_input +\"\"\"\\n\\nReview:\\n{}\\n\\nAction:\\n{}\\n\"\"\".format(row[\"Customer_Service\"], row[\"Action\"])", "execution_count": 46, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "prompt = Prompt(access_token, project_id)", "execution_count": 47, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\n\ntest_data[\"Predicted_Action\"] = 0\nfor index, row in test_data.loc[test_data['Satisfaction'] == 0].iterrows():\n    #test = test + \"\"\"\\nReview:\\n{}\\n\\nClassification:\\n\"\"\".format(row[\"Customer_Service\"])\n    generated_response = prompt.generate(prompt_input + \"\"\"\\nReview:\\n{}\\n\\nAction:\\n\"\"\".format(row[\"Customer_Service\"]), model_id, parameters)\n    test_data.at[index, \"Predicted_Action\"] = generated_response", "execution_count": 48, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#test_data[[\"Action\", \"Predicted_Action\"]].head()", "execution_count": 50, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Analyze the recommended actions for inputs from the test set.\n\n**Note:** Execution of this cell could take several minutes."}, {"metadata": {}, "cell_type": "code", "source": "test_data[\"Action\"] = np.where(test_data[\"Action\"].isnull(), 0, test_data[\"Action\"])\ntest_data[\"Predicted_Action\"] = np.where(test_data[\"Predicted_Action\"].isnull(), 0, test_data[\"Predicted_Action\"])", "execution_count": 53, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Calculate the F1 micro score"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import f1_score\n\nprint('f1_micro_score', f1_score(test_data[\"Action\"].astype(str), test_data[\"Predicted_Action\"].astype(str), average='micro'))", "execution_count": 54, "outputs": [{"output_type": "stream", "text": "f1_micro_score 0.82\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "---"}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the MIT License."}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}